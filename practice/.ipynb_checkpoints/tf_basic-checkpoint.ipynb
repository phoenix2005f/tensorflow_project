{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phx/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "train_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "x_ , y_ = digits.data , digits.target\n",
    "\n",
    "\n",
    "x_ = x_ / x_.max()\n",
    "## one hot\n",
    "y_ = np.eye(10)[y_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 照y_分類比例去切資料集\n",
    "X_train , X_test , y_train , y_test = train_test_split(x_ , y_ , test_size=0.05 , stratify = y_)\n",
    "\n",
    "# 切驗證集\n",
    "X_train , X_valid , y_train , y_valid = train_test_split(X_train , y_train , test_size=1-train_ratio , stratify = y_train.argmax(axis=1))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定義variables and bias, (25,25,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "    ## 這邊要用Variable,系統會偵測命名衝突,get_variable會出錯\n",
    "    return tf.Variable(tf.random_normal(shape=shape,stddev=0.02))\n",
    "def init_bias(shape):\n",
    "    return tf.Variable(tf.zeros(shape=shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class net1:\n",
    "    def __init__(self  , img_shape):\n",
    "        \n",
    "      \n",
    "        self.hidden_num = [25,25,25,10]\n",
    "        \n",
    "        with tf.variable_scope('hidden_layer'):\n",
    "            self.w1 = init_weights([img_shape[1],self.hidden_num[0]])\n",
    "            self.b1 = init_bias([self.hidden_num[0]])\n",
    "            \n",
    "            self.w2 = init_weights([self.hidden_num[0],self.hidden_num[1]])\n",
    "            self.b2 = init_bias([self.hidden_num[1]])\n",
    "            \n",
    "            self.w3 = init_weights([self.hidden_num[1],self.hidden_num[2]])\n",
    "            self.b3 = init_bias([self.hidden_num[2]])\n",
    "            \n",
    "            self.w4 = init_weights([self.hidden_num[2],self.hidden_num[3] ])\n",
    "            self.b4 = init_bias([self.hidden_num[3]])\n",
    "        \n",
    "    def forward(self,X):\n",
    "        z = tf.nn.relu( tf.add(tf.matmul(X,self.w1) , self.b1))\n",
    "        z = tf.nn.relu( tf.add(tf.matmul(z,self.w2) , self.b2))\n",
    "        z = tf.nn.relu( tf.add(tf.matmul(z,self.w3) , self.b3))\n",
    "        z = tf.nn.relu( tf.add(tf.matmul(z,self.w4) , self.b4))\n",
    "        return z\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class model:\n",
    "    def __init__(self,x_train,y_train,x_valid,y_valid,batch_size=32,epochs=20,lr=0.001):\n",
    "        self.epochs = epochs\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.x_valid = x_valid\n",
    "        self.y_valid = y_valid\n",
    "        \n",
    "        self.x_shape = x_train.shape\n",
    "        self.y_shape = y_train.shape\n",
    "        self.batch_size = batch_size\n",
    "        self.net_model = net1(img_shape)\n",
    "        \n",
    "        #定義graph\n",
    "        self.X = tf.placeholder(dtype=tf.float32,shape=[None,self.x_shape[1]])\n",
    "        self.y = tf.placeholder(dtype=tf.float32,shape=[None,self.y_shape[1]])\n",
    "        \n",
    "        self.out = self.net_model.forward(self.X)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=self.out,labels=self.y))\n",
    "        \n",
    "        train_vars = tf.trainable_variables()\n",
    "        net_vars = [ var for var in train_vars if 'hidden_layer' in var.name]\n",
    "        \n",
    "        self.step = tf.train.AdamOptimizer(learning_rate=lr).minimize(self.loss,var_list=net_vars)\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        \n",
    "        init = tf.global_variables_initializer()\n",
    "        self.train_losses=[]\n",
    "        self.valid_losses=[]\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(init)\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            total_batch = int(np.floor(self.x_shape[0]/self.batch_size))\n",
    "            train_losses=[]\n",
    "            for j in range(total_batch):\n",
    "                batch_idx_start = j*self.batch_size\n",
    "                batch_idx_end = (j+1)*self.batch_size\n",
    "                \n",
    "                x_batch = self.x_train[batch_idx_start:batch_idx_end]\n",
    "                y_batch = self.y_train[batch_idx_start:batch_idx_end]\n",
    "                train_loss_ , _ = self.sess.run([self.loss,self.step],feed_dict={self.X:x_batch , self.y:y_batch})\n",
    "                train_losses.append(train_loss_)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "            valid_loss_ = self.sess.run(self.loss,feed_dict={self.X:self.x_valid,self.y:self.y_valid})\n",
    "                \n",
    "            print(\"{}/{}: train loss: {:.4f} ,  valid loss: {:.4f}\".format(i+1,self.epochs,sum(train_losses)/batch_size , valid_loss_))  \n",
    "            self.train_losses.append(sum(train_losses)/batch_size)\n",
    "            self.valid_losses.append(valid_loss_)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-ea907f12efab>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "1/100: train loss: 3.4527 ,  valid loss: 2.2966\n",
      "2/100: train loss: 3.3635 ,  valid loss: 2.1182\n",
      "3/100: train loss: 3.0881 ,  valid loss: 2.0194\n",
      "4/100: train loss: 3.0057 ,  valid loss: 1.9865\n",
      "5/100: train loss: 2.9658 ,  valid loss: 1.9664\n",
      "6/100: train loss: 2.9240 ,  valid loss: 1.9402\n",
      "7/100: train loss: 2.8562 ,  valid loss: 1.8914\n",
      "8/100: train loss: 2.7594 ,  valid loss: 1.8268\n",
      "9/100: train loss: 2.6561 ,  valid loss: 1.7689\n",
      "10/100: train loss: 2.5807 ,  valid loss: 1.7325\n",
      "11/100: train loss: 2.5385 ,  valid loss: 1.7126\n",
      "12/100: train loss: 2.5135 ,  valid loss: 1.6993\n",
      "13/100: train loss: 2.4970 ,  valid loss: 1.6896\n",
      "14/100: train loss: 2.4861 ,  valid loss: 1.6823\n",
      "15/100: train loss: 2.4783 ,  valid loss: 1.6767\n",
      "16/100: train loss: 2.4724 ,  valid loss: 1.6732\n",
      "17/100: train loss: 2.4677 ,  valid loss: 1.6700\n",
      "18/100: train loss: 2.4639 ,  valid loss: 1.6674\n",
      "19/100: train loss: 2.4608 ,  valid loss: 1.6650\n",
      "20/100: train loss: 2.4584 ,  valid loss: 1.6634\n",
      "21/100: train loss: 2.4563 ,  valid loss: 1.6625\n",
      "22/100: train loss: 2.4545 ,  valid loss: 1.6622\n",
      "23/100: train loss: 2.4530 ,  valid loss: 1.6616\n",
      "24/100: train loss: 2.4518 ,  valid loss: 1.6619\n",
      "25/100: train loss: 2.4506 ,  valid loss: 1.6625\n",
      "26/100: train loss: 2.4498 ,  valid loss: 1.6623\n",
      "27/100: train loss: 2.4491 ,  valid loss: 1.6640\n",
      "28/100: train loss: 2.4482 ,  valid loss: 1.6647\n",
      "29/100: train loss: 2.4476 ,  valid loss: 1.6643\n",
      "30/100: train loss: 2.4471 ,  valid loss: 1.6662\n",
      "31/100: train loss: 2.4466 ,  valid loss: 1.6673\n",
      "32/100: train loss: 2.4462 ,  valid loss: 1.6689\n",
      "33/100: train loss: 2.4460 ,  valid loss: 1.6716\n",
      "34/100: train loss: 2.4458 ,  valid loss: 1.6732\n",
      "35/100: train loss: 2.4455 ,  valid loss: 1.6745\n",
      "36/100: train loss: 2.4452 ,  valid loss: 1.6751\n",
      "37/100: train loss: 2.4451 ,  valid loss: 1.6778\n",
      "38/100: train loss: 2.4447 ,  valid loss: 1.6763\n",
      "39/100: train loss: 2.4443 ,  valid loss: 1.6773\n",
      "40/100: train loss: 2.4443 ,  valid loss: 1.6773\n",
      "41/100: train loss: 2.4439 ,  valid loss: 1.6765\n",
      "42/100: train loss: 2.4437 ,  valid loss: 1.6772\n",
      "43/100: train loss: 2.4435 ,  valid loss: 1.6788\n",
      "44/100: train loss: 2.4433 ,  valid loss: 1.6787\n",
      "45/100: train loss: 2.4431 ,  valid loss: 1.6808\n",
      "46/100: train loss: 2.4431 ,  valid loss: 1.6799\n",
      "47/100: train loss: 2.4430 ,  valid loss: 1.6791\n",
      "48/100: train loss: 2.4429 ,  valid loss: 1.6806\n",
      "49/100: train loss: 2.4428 ,  valid loss: 1.6802\n",
      "50/100: train loss: 2.4428 ,  valid loss: 1.6803\n",
      "51/100: train loss: 2.4448 ,  valid loss: 1.6653\n",
      "52/100: train loss: 2.4411 ,  valid loss: 1.6828\n",
      "53/100: train loss: 2.4406 ,  valid loss: 1.6861\n",
      "54/100: train loss: 2.4406 ,  valid loss: 1.6906\n",
      "55/100: train loss: 2.4405 ,  valid loss: 1.6894\n",
      "56/100: train loss: 2.4404 ,  valid loss: 1.6871\n",
      "57/100: train loss: 2.4403 ,  valid loss: 1.6884\n",
      "58/100: train loss: 2.4403 ,  valid loss: 1.6924\n",
      "59/100: train loss: 2.4402 ,  valid loss: 1.6899\n",
      "60/100: train loss: 2.4404 ,  valid loss: 1.6870\n",
      "61/100: train loss: 2.4401 ,  valid loss: 1.6834\n",
      "62/100: train loss: 2.4402 ,  valid loss: 1.6916\n",
      "63/100: train loss: 2.4402 ,  valid loss: 1.6887\n",
      "64/100: train loss: 2.4402 ,  valid loss: 1.6892\n",
      "65/100: train loss: 2.4401 ,  valid loss: 1.6919\n",
      "66/100: train loss: 2.4401 ,  valid loss: 1.6894\n",
      "67/100: train loss: 2.4401 ,  valid loss: 1.6862\n",
      "68/100: train loss: 2.4401 ,  valid loss: 1.6973\n",
      "69/100: train loss: 2.4400 ,  valid loss: 1.6977\n",
      "70/100: train loss: 2.4400 ,  valid loss: 1.6955\n",
      "71/100: train loss: 2.4400 ,  valid loss: 1.6936\n",
      "72/100: train loss: 2.4400 ,  valid loss: 1.6880\n",
      "73/100: train loss: 2.4400 ,  valid loss: 1.6981\n",
      "74/100: train loss: 2.4401 ,  valid loss: 1.6906\n",
      "75/100: train loss: 2.4400 ,  valid loss: 1.6919\n",
      "76/100: train loss: 2.4400 ,  valid loss: 1.6944\n",
      "77/100: train loss: 2.4399 ,  valid loss: 1.6957\n",
      "78/100: train loss: 2.4401 ,  valid loss: 1.7002\n",
      "79/100: train loss: 2.4400 ,  valid loss: 1.6922\n",
      "80/100: train loss: 2.4399 ,  valid loss: 1.6964\n",
      "81/100: train loss: 2.4400 ,  valid loss: 1.6945\n",
      "82/100: train loss: 2.4400 ,  valid loss: 1.6970\n",
      "83/100: train loss: 2.4399 ,  valid loss: 1.7067\n",
      "84/100: train loss: 2.4399 ,  valid loss: 1.7014\n",
      "85/100: train loss: 2.4399 ,  valid loss: 1.7093\n",
      "86/100: train loss: 2.4400 ,  valid loss: 1.6953\n",
      "87/100: train loss: 2.4399 ,  valid loss: 1.7036\n",
      "88/100: train loss: 2.4399 ,  valid loss: 1.7038\n",
      "89/100: train loss: 2.4399 ,  valid loss: 1.7052\n",
      "90/100: train loss: 2.4399 ,  valid loss: 1.7094\n",
      "91/100: train loss: 2.4399 ,  valid loss: 1.7072\n",
      "92/100: train loss: 2.4400 ,  valid loss: 1.6915\n",
      "93/100: train loss: 2.4399 ,  valid loss: 1.7070\n",
      "94/100: train loss: 2.4399 ,  valid loss: 1.7107\n",
      "95/100: train loss: 2.4399 ,  valid loss: 1.7098\n",
      "96/100: train loss: 2.4399 ,  valid loss: 1.7126\n",
      "97/100: train loss: 2.4401 ,  valid loss: 1.7073\n",
      "98/100: train loss: 2.4399 ,  valid loss: 1.7057\n",
      "99/100: train loss: 2.4398 ,  valid loss: 1.7045\n",
      "100/100: train loss: 2.4399 ,  valid loss: 1.7063\n"
     ]
    }
   ],
   "source": [
    "model1 = model(X_train,y_train,X_valid,y_valid,epochs=100)\n",
    "model1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8IuI5BkFv4hInlHwi4jkmf8P29ej9Ujq0PYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11db02748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(len(model1.train_losses)), model1.train_losses, 'b', label = 'train')\n",
    "plt.plot(np.arange(len(model1.valid_losses)), model1.valid_losses, 'r', label = 'valid')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
